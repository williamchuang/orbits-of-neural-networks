\providecommand{\bysame}{\leavevmode\hbox to3em{\hrulefill}\thinspace}
\providecommand{\MR}{\relax\ifhmode\unskip\space\fi MR }
% \MRhref is called by the amsart/book/proc definition of \MR.
\providecommand{\MRhref}[2]{%
  \href{http://www.ams.org/mathscinet-getitem?mr=#1}{#2}
}
\providecommand{\href}[2]{#2}
\begin{thebibliography}{10}

\bibitem{MR725161}
Lars~V. Ahlfors, \emph{M\"{o}bius transformations in several dimensions},
  Ordway Professorship Lectures in Mathematics, University of Minnesota, School
  of Mathematics, Minneapolis, Minn., 1981. \MR{725161}

\bibitem{athalye2018obfuscated}
Anish Athalye, Nicholas Carlini, and David Wagner, \emph{Obfuscated gradients
  give a false sense of security: Circumventing defenses to adversarial
  examples}, International conference on machine learning, PMLR, 2018,
  pp.~274--283.

\bibitem{beardon2012geometry}
Alan~F. Beardon, \emph{The geometry of discrete groups}, Graduate Texts in
  Mathematics, vol.~91, Springer-Verlag, New York, 1995, Corrected reprint of
  the 1983 original. \MR{1393195}

\bibitem{benedetti20072+}
Riccardo Benedetti and Francesco Bonsante, \emph{(2+1)-{E}instein spacetimes of
  finite type}, arXiv preprint arXiv:0704.2152 (2007).

\bibitem{bers1981finite}
Lipman Bers, \emph{Finite dimensional teichm{\"u}ller spaces and
  generalizations}, Bulletin of the American Mathematical Society \textbf{5}
  (1981), no.~2, 131--172.

\bibitem{blum1988training}
Avrim Blum and Ronald Rivest, \emph{Training a 3-node neural network is
  np-complete}, Advances in neural information processing systems \textbf{1}
  (1988).

\bibitem{borthwick2007spectral}
David Borthwick, \emph{Spectral theory of infinite-area hyperbolic surfaces},
  second ed., Progress in Mathematics, vol. 318, Birkh\"{a}user/Springer,
  [Cham], 2016. \MR{3497464}

\bibitem{bronstein2021geometric}
Michael~M Bronstein, Joan Bruna, Taco Cohen, and Petar Veli{\v{c}}kovi{\'c},
  \emph{Geometric deep learning: Grids, groups, graphs, geodesics, and gauges},
  arXiv preprint arXiv:2104.13478 (2021).

\bibitem{cheng1980existence}
Shiu-Yuen Cheng and Shing-Tung Yau, \emph{On the existence of a complete
  k{\"a}hler metric on non-compact complex manifolds and the regularity of
  fefferman's equation}, Communications on Pure and Applied Mathematics
  \textbf{33} (1980), no.~4, 507--544.

\bibitem{choromanska2015loss}
Anna Choromanska, Mikael Henaff, Michael Mathieu, G{\'e}rard~Ben Arous, and
  Yann LeCun, \emph{The loss surfaces of multilayer networks}, Artificial
  intelligence and statistics, PMLR, 2015, pp.~192--204.

\bibitem{chuang2022hausdorff}
William~Huanshan Chuang, \emph{The hausdorff dimension of limit sets of
  well-distributed schottky groups}, 2022.

\bibitem{chuang2015implications}
\bysame, \emph{An invariant between hyperbolic surfaces and lattice spin
  models}, arXiv preprint arXiv:1511.02291 (2023).

\bibitem{dinh2017sharp}
Laurent Dinh, Razvan Pascanu, Samy Bengio, and Yoshua Bengio, \emph{Sharp
  minima can generalize for deep nets}, International Conference on Machine
  Learning, PMLR, 2017, pp.~1019--1028.

\bibitem{draxler2018essentially}
Felix Draxler, Kambis Veschgini, Manfred Salmhofer, and Fred Hamprecht,
  \emph{Essentially no barriers in neural network energy landscape},
  International conference on machine learning, PMLR, 2018, pp.~1309--1318.

\bibitem{du2019gradient}
Simon Du, Jason Lee, Haochuan Li, Liwei Wang, and Xiyu Zhai, \emph{Gradient
  descent finds global minima of deep neural networks}, International
  conference on machine learning, PMLR, 2019, pp.~1675--1685.

\bibitem{ford2004automorphic}
Lester~R Ford, \emph{Automorphic functions}, vol.~85, American Mathematical
  Soc., 2004.

\bibitem{freeman2016topology}
C~Daniel Freeman and Joan Bruna, \emph{Topology and geometry of half-rectified
  network optimization}, arXiv preprint arXiv:1611.01540 (2016).

\bibitem{garipov2018loss}
Timur Garipov, Pavel Izmailov, Dmitrii Podoprikhin, Dmitry~P Vetrov, and
  Andrew~G Wilson, \emph{Loss surfaces, mode connectivity, and fast ensembling
  of dnns}, Advances in neural information processing systems \textbf{31}
  (2018).

\bibitem{goodfellow2014qualitatively}
Ian~J Goodfellow, Oriol Vinyals, and Andrew~M Saxe, \emph{Qualitatively
  characterizing neural network optimization problems}, arXiv preprint
  arXiv:1412.6544 (2014).

\bibitem{gromov1981hyperbolic}
Mikhael Gromov, \emph{Hyperbolic manifolds, groups and actions}, Riemann
  surfaces and related topics: Proceedings of the 1978 Stony Brook Conference
  (State Univ. New York, Stony Brook, NY, 1978), vol.~97, 1981, pp.~183--213.

\bibitem{hori2003mirror}
Kentaro Hori, Sheldon Katz, Albrecht Klemm, Rahul Pandharipande, Richard
  Thomas, Cumrun Vafa, Ravi Vakil, and Eric Zaslow, \emph{Mirror symmetry},
  vol.~1, American Mathematical Soc., 2003.

\bibitem{im2016empirical}
Daniel~Jiwoong Im, Michael Tao, and Kristin Branson, \emph{An empirical
  analysis of deep network loss surfaces},  (2016).

\bibitem{jacquet2006automorphic}
Herv{\'e} Jacquet and Robert~P Langlands, \emph{Automorphic forms on gl (2):
  Part 1}, vol. 114, Springer, 2006.

\bibitem{judd1990neural}
J~Stephen Judd, \emph{Neural network design and the complexity of learning},
  MIT press, 1990.

\bibitem{MR1138441}
M.~\`E. Kapovich and L.~D. Potyaga\u{\i}lo, \emph{On the absence of finiteness
  theorems of {A}hlfors and {S}ullivan for {K}leinian groups in higher
  dimensions}, Sibirsk. Mat. Zh. \textbf{32} (1991), no.~2, 61--73, 212.
  \MR{1138441}

\bibitem{MR2402415}
Michael Kapovich, \emph{Kleinian groups in higher dimensions}, Geometry and
  dynamics of groups and spaces, Progr. Math., vol. 265, Birkh\"{a}user, Basel,
  2008, pp.~487--564. \MR{2402415}

\bibitem{kawaguchi2017generalization}
Kenji Kawaguchi, Leslie~Pack Kaelbling, and Yoshua Bengio, \emph{Generalization
  in deep learning}, arXiv preprint arXiv:1710.05468 \textbf{1} (2017), no.~8.

\bibitem{kumar2023black}
Pranav Kumar, Taniya Mandal, and Swapnamay Mondal, \emph{Black holes and the
  loss landscape in machine learning}, arXiv preprint arXiv:2306.14817 (2023).

\bibitem{li2018visualizing}
Hao Li, Zheng Xu, Gavin Taylor, Christoph Studer, and Tom Goldstein,
  \emph{Visualizing the loss landscape of neural nets}, Advances in neural
  information processing systems \textbf{31} (2018).

\bibitem{louart2018random}
Cosme Louart, Zhenyu Liao, and Romain Couillet, \emph{A random matrix approach
  to neural networks}, The Annals of Applied Probability \textbf{28} (2018),
  no.~2, 1190--1248.

\bibitem{lucas2022optimization}
James Lucas, \emph{Optimization and loss landscape geometry of deep learning},
  Ph.D. thesis, University of Toronto (Canada), 2022.

\bibitem{ma2018mode}
Shiqing Ma, Yingqi Liu, Wen-Chuan Lee, Xiangyu Zhang, and Ananth Grama,
  \emph{Mode: automated neural network model debugging via state differential
  analysis and input selection}, Proceedings of the 2018 26th ACM Joint Meeting
  on European Software Engineering Conference and Symposium on the Foundations
  of Software Engineering, 2018, pp.~175--186.

\bibitem{malan2021survey}
Katherine~Mary Malan, \emph{A survey of advances in landscape analysis for
  optimisation}, Algorithms \textbf{14} (2021), no.~2, 40.

\bibitem{mcmullen1992riemann}
Curt McMullen, \emph{Riemann surfaces and the geometrization of 3-manifolds},
  Bulletin of the American mathematical society \textbf{27} (1992), no.~2,
  207--216.

\bibitem{misner1973gravitation}
Charles~W Misner, Kip~S Thorne, and John~Archibald Wheeler, \emph{Gravitation},
  Macmillan, 1973.

\bibitem{neyshabur2017exploring}
Behnam Neyshabur, Srinadh Bhojanapalli, David McAllester, and Nati Srebro,
  \emph{Exploring generalization in deep learning}, Advances in neural
  information processing systems \textbf{30} (2017).

\bibitem{nguyen2017loss}
Quynh Nguyen and Matthias Hein, \emph{The loss surface of deep and wide neural
  networks}, International conference on machine learning, PMLR, 2017,
  pp.~2603--2612.

\bibitem{nguyen2018loss}
Quynh Nguyen, Mahesh~Chandra Mukkamala, and Matthias Hein, \emph{On the loss
  landscape of a class of deep neural networks with no bad local valleys},
  arXiv preprint arXiv:1809.10749 (2018).

\bibitem{nlab:selberg_zeta_function}
{nLab authors}, \emph{{{S}}elberg zeta function},
  \url{https://ncatlab.org/nlab/show/Selberg+zeta+function}, November 2023,
  \href{https://ncatlab.org/nlab/revision/Selberg+zeta+function/14}{Revision
  14}.

\bibitem{pennington2017geometry}
Jeffrey Pennington and Yasaman Bahri, \emph{Geometry of neural network loss
  surfaces via random matrix theory}, International conference on machine
  learning, PMLR, 2017, pp.~2798--2806.

\bibitem{poole2016exponential}
Ben Poole, Subhaneil Lahiri, Maithra Raghu, Jascha Sohl-Dickstein, and Surya
  Ganguli, \emph{Exponential expressivity in deep neural networks through
  transient chaos}, Advances in neural information processing systems
  \textbf{29} (2016).

\bibitem{MR4221225}
John~G. Ratcliffe, \emph{Foundations of hyperbolic manifolds}, Graduate Texts
  in Mathematics, vol. 149, Springer, Cham, [2019] \copyright 2019, Third
  edition [of 1299730]. \MR{4221225}

\bibitem{MR1893917}
Jos\'{e} Seade and Alberto Verjovsky, \emph{Higher dimensional complex
  {K}leinian groups}, Math. Ann. \textbf{322} (2002), no.~2, 279--300.
  \MR{1893917}

\bibitem{seddik2020random}
Mohamed El~Amine Seddik, Cosme Louart, Mohamed Tamaazousti, and Romain
  Couillet, \emph{Random matrix theory proves that deep learning
  representations of gan-data behave as gaussian mixtures}, International
  Conference on Machine Learning, PMLR, 2020, pp.~8573--8582.

\bibitem{seppala2011geometry}
Mika Sepp{\"a}l{\"a} and Tuomas Sorvali, \emph{Geometry of riemann surfaces and
  teichm{\"u}ller spaces}, Elsevier, 2011.

\bibitem{sullivan1979hyperbolic}
Dennis Sullivan, \emph{Hyperbolic geometry and homeomorphisms}, Geometric
  topology, Elsevier, 1979, pp.~543--555.

\bibitem{thurston1982three}
William~P Thurston, \emph{Three dimensional manifolds, kleinian groups and
  hyperbolic geometry},  (1982).

\bibitem{thurston2022geometry}
\bysame, \emph{The geometry and topology of three-manifolds: With a preface by
  steven p. kerckhoff}, vol.~27, American Mathematical Society, 2022.

\bibitem{tramer2017ensemble}
Florian Tram{\`e}r, Alexey Kurakin, Nicolas Papernot, Ian Goodfellow, Dan
  Boneh, and Patrick McDaniel, \emph{Ensemble adversarial training: Attacks and
  defenses}, arXiv preprint arXiv:1705.07204 (2017).

\bibitem{tu2011manifolds}
Loring~W Tu, \emph{Manifolds}, An Introduction to Manifolds, Springer, 2011.

\bibitem{vaswani2017attention}
Ashish Vaswani, Noam Shazeer, Niki Parmar, Jakob Uszkoreit, Llion Jones,
  Aidan~N Gomez, {\L}ukasz Kaiser, and Illia Polosukhin, \emph{Attention is all
  you need}, Advances in neural information processing systems \textbf{30}
  (2017).

\bibitem{yun2017global}
Chulhee Yun, Suvrit Sra, and Ali Jadbabaie, \emph{Global optimality conditions
  for deep neural networks}, arXiv preprint arXiv:1707.02444 (2017).

\bibitem{zhang2021embedding}
Yaoyu Zhang, Zhongwang Zhang, Tao Luo, and Zhiqin~J Xu, \emph{Embedding
  principle of loss landscape of deep neural networks}, Advances in Neural
  Information Processing Systems \textbf{34} (2021), 14848--14859.

\bibitem{zhang2022toward}
Yingyi Zhang, Zan Wang, Jiajun Jiang, Hanmo You, and Junjie Chen, \emph{Toward
  improving the robustness of deep learning models via model transformation},
  Proceedings of the 37th IEEE/ACM International Conference on Automated
  Software Engineering, 2022, pp.~1--13.

\end{thebibliography}
