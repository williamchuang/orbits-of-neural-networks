\relax 
\providecommand\hyper@newdestlabel[2]{}
\providecommand\babel@aux[2]{}
\@nameuse{bbl@beforestart}
\providecommand\HyperFirstAtBeginDocument{\AtBeginDocument}
\HyperFirstAtBeginDocument{\ifx\hyper@anchor\@undefined
\global\let\oldcontentsline\contentsline
\gdef\contentsline#1#2#3#4{\oldcontentsline{#1}{#2}{#3}}
\global\let\oldnewlabel\newlabel
\gdef\newlabel#1#2{\newlabelxx{#1}#2}
\gdef\newlabelxx#1#2#3#4#5#6{\oldnewlabel{#1}{{#2}{#3}}}
\AtEndDocument{\ifx\hyper@anchor\@undefined
\let\contentsline\oldcontentsline
\let\newlabel\oldnewlabel
\fi}
\fi}
\global\let\hyper@last\relax 
\gdef\HyperFirstAtBeginDocument#1{#1}
\providecommand\HyField@AuxAddToFields[1]{}
\providecommand\HyField@AuxAddToCoFields[2]{}
\citation{ma2018mode}
\citation{tramer2017ensemble}
\citation{athalye2018obfuscated}
\citation{yun2017global}
\citation{blum1988training}
\citation{judd1990neural}
\providecommand \oddpage@label [2]{}
\babel@aux{english}{}
\@writefile{toc}{\contentsline {section}{\numberline {1}Introduction}{1}{section.1}\protected@file@percent }
\citation{tu2011manifolds}
\@writefile{toc}{\contentsline {section}{\numberline {2}Hyperbolic-length Product}{3}{section.2}\protected@file@percent }
\citation{beardon2012geometry}
\citation{MR1138441}
\citation{MR725161}
\citation{beardon2012geometry}
\citation{MR2402415}
\citation{MR4221225}
\citation{MR1893917}
\@writefile{toc}{\contentsline {section}{\numberline {3}Hyperbolic-orbit Algorithm}{6}{section.3}\protected@file@percent }
\@writefile{lof}{\contentsline {figure}{\numberline {1}{\ignorespaces The computational graph of case 1.}}{8}{figure.1}\protected@file@percent }
\@writefile{lof}{\contentsline {figure}{\numberline {2}{\ignorespaces An illustration on how to embed \textbf  {any} given product of matrices $AB$ in \textbf  {any neural network models} to hyperbolic space $\mathbb  {H}^2$.}}{9}{figure.2}\protected@file@percent }
\citation{vaswani2017attention}
\citation{chuang2022hausdorff}
\@writefile{lof}{\contentsline {figure}{\numberline {3}{\ignorespaces The computational graph of Case 2 when a hyperbolic-length product is implemented to the model directly before training.}}{10}{figure.3}\protected@file@percent }
\@writefile{toc}{\contentsline {section}{\numberline {4}Examples}{10}{section.4}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {4.1}Self-attention mechanism in any transformer-based models with the hyperbolic-length product implemented before training}{10}{subsection.4.1}\protected@file@percent }
\@writefile{toc}{\contentsline {section}{\numberline {5}Empirical Results}{10}{section.5}\protected@file@percent }
\@writefile{toc}{\contentsline {section}{\numberline {6}Discussion}{11}{section.6}\protected@file@percent }
\citation{blum1988training}
\citation{cheng1980existence}
\@writefile{lof}{\contentsline {figure}{\numberline {4}{\ignorespaces Using an open set $B_r(p)$ centered at $p\in \mathbb  {H}^2$ with radius $r>0$ that covers all embedded weights of the given converged model to study the correspondence between the location of $B_r(p)$ in $\mathbb  {H}^2$ and the location of the model in the loss surface.}}{13}{figure.4}\protected@file@percent }
\citation{chuang2015implications}
\@writefile{lof}{\contentsline {figure}{\numberline {5}{\ignorespaces Focusing on a two-generator subgroup of $\text  {PSL}(2,\mathbb  {R})$ (it can be called a Schottky group, Fuchsian group, or Kleinian group) and its fundamental domain in $\mathbb  {H}^2$.}}{15}{figure.5}\protected@file@percent }
\@writefile{lof}{\contentsline {figure}{\numberline {6}{\ignorespaces Possible scenarios of loss surface. Each possible scenario of the new loss surface after applying fractional linear mapping (which is corresponding to an element to the two-generator group) to the weights of the given converged model. Notice that it is possible that the model was mapped to the deleted neighborhood of a new local minimum or the global minimum.}}{16}{figure.6}\protected@file@percent }
\citation{zhang2022toward}
\bibstyle{amsplain}
\bibdata{refs}
\bibcite{MR725161}{1}
\bibcite{athalye2018obfuscated}{2}
\bibcite{beardon2012geometry}{3}
\bibcite{blum1988training}{4}
\bibcite{cheng1980existence}{5}
\bibcite{chuang2022hausdorff}{6}
\bibcite{chuang2015implications}{7}
\bibcite{judd1990neural}{8}
\bibcite{MR1138441}{9}
\bibcite{MR2402415}{10}
\bibcite{ma2018mode}{11}
\bibcite{MR4221225}{12}
\bibcite{MR1893917}{13}
\bibcite{tramer2017ensemble}{14}
\bibcite{tu2011manifolds}{15}
\bibcite{vaswani2017attention}{16}
\bibcite{yun2017global}{17}
\bibcite{zhang2022toward}{18}
\gdef \@abspage@last{19}
