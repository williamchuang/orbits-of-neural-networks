\relax 
\providecommand\hyper@newdestlabel[2]{}
\providecommand\babel@aux[2]{}
\@nameuse{bbl@beforestart}
\providecommand\HyperFirstAtBeginDocument{\AtBeginDocument}
\HyperFirstAtBeginDocument{\ifx\hyper@anchor\@undefined
\global\let\oldcontentsline\contentsline
\gdef\contentsline#1#2#3#4{\oldcontentsline{#1}{#2}{#3}}
\global\let\oldnewlabel\newlabel
\gdef\newlabel#1#2{\newlabelxx{#1}#2}
\gdef\newlabelxx#1#2#3#4#5#6{\oldnewlabel{#1}{{#2}{#3}}}
\AtEndDocument{\ifx\hyper@anchor\@undefined
\let\contentsline\oldcontentsline
\let\newlabel\oldnewlabel
\fi}
\fi}
\global\let\hyper@last\relax 
\gdef\HyperFirstAtBeginDocument#1{#1}
\providecommand\HyField@AuxAddToFields[1]{}
\providecommand\HyField@AuxAddToCoFields[2]{}
\citation{yun2017global}
\citation{blum1988training}
\citation{judd1990neural}
\citation{tu2011manifolds}
\providecommand \oddpage@label [2]{}
\babel@aux{english}{}
\@writefile{toc}{\contentsline {section}{\numberline {1}Introduction}{1}{section.1}\protected@file@percent }
\citation{beardon2012geometry}
\@writefile{toc}{\contentsline {section}{\numberline {2}Hyperbolic-orbit Algorithm}{3}{section.2}\protected@file@percent }
\citation{MR1138441}
\citation{MR725161}
\citation{beardon2012geometry}
\citation{MR2402415}
\citation{MR4221225}
\citation{MR1893917}
\@writefile{lof}{\contentsline {figure}{\numberline {1}{\ignorespaces Gradients of the hyperbolic-length product.}}{7}{figure.1}\protected@file@percent }
\@writefile{lof}{\contentsline {figure}{\numberline {2}{\ignorespaces The computational graph of Case 2 when both $AB$ and $C$ are invertible.}}{7}{figure.2}\protected@file@percent }
\citation{vaswani2017attention}
\@writefile{lof}{\contentsline {figure}{\numberline {3}{\ignorespaces The computational graph of Case 2 when $C$ is invertible, and $AB$ is not invertible.}}{8}{figure.3}\protected@file@percent }
\@writefile{lof}{\contentsline {figure}{\numberline {4}{\ignorespaces The computational graph of Case 2 when both $AB$ and $C$ are not invertible.}}{8}{figure.4}\protected@file@percent }
\@writefile{lof}{\contentsline {figure}{\numberline {5}{\ignorespaces The computational graph of Case 2 when a hyperbolic-length product is implemented to the model directly before training.}}{8}{figure.5}\protected@file@percent }
\citation{blum1988training}
\@writefile{toc}{\contentsline {section}{\numberline {3}Examples}{9}{section.3}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {3.1}Self-attention mechanism in any transformer-based models with the hyperbolic-length product implemented before training}{9}{subsection.3.1}\protected@file@percent }
\@writefile{toc}{\contentsline {section}{\numberline {4}Discussion}{9}{section.4}\protected@file@percent }
\bibstyle{amsplain}
\bibdata{refs}
\bibcite{MR725161}{1}
\bibcite{beardon2012geometry}{2}
\@writefile{toc}{\contentsline {section}{\numberline {5}Limitation}{10}{section.5}\protected@file@percent }
\bibcite{blum1988training}{3}
\bibcite{judd1990neural}{4}
\bibcite{MR1138441}{5}
\bibcite{MR2402415}{6}
\bibcite{MR4221225}{7}
\bibcite{MR1893917}{8}
\bibcite{tu2011manifolds}{9}
\bibcite{vaswani2017attention}{10}
\bibcite{yun2017global}{11}
\gdef \@abspage@last{11}
