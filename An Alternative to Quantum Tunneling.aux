\relax 
\providecommand\hyper@newdestlabel[2]{}
\providecommand\babel@aux[2]{}
\@nameuse{bbl@beforestart}
\providecommand\HyperFirstAtBeginDocument{\AtBeginDocument}
\HyperFirstAtBeginDocument{\ifx\hyper@anchor\@undefined
\global\let\oldcontentsline\contentsline
\gdef\contentsline#1#2#3#4{\oldcontentsline{#1}{#2}{#3}}
\global\let\oldnewlabel\newlabel
\gdef\newlabel#1#2{\newlabelxx{#1}#2}
\gdef\newlabelxx#1#2#3#4#5#6{\oldnewlabel{#1}{{#2}{#3}}}
\AtEndDocument{\ifx\hyper@anchor\@undefined
\let\contentsline\oldcontentsline
\let\newlabel\oldnewlabel
\fi}
\fi}
\global\let\hyper@last\relax 
\gdef\HyperFirstAtBeginDocument#1{#1}
\providecommand\HyField@AuxAddToFields[1]{}
\providecommand\HyField@AuxAddToCoFields[2]{}
\citation{yun2017global}
\citation{blum1988training}
\citation{judd1990neural}
\citation{tu2011manifolds}
\providecommand \oddpage@label [2]{}
\babel@aux{english}{}
\@writefile{toc}{\contentsline {section}{\numberline {1}Introduction}{1}{section.1}\protected@file@percent }
\@writefile{toc}{\contentsline {section}{\numberline {2}Hyperbolic-length Product}{3}{section.2}\protected@file@percent }
\citation{beardon2012geometry}
\citation{MR1138441}
\citation{MR725161}
\citation{beardon2012geometry}
\citation{MR2402415}
\citation{MR4221225}
\citation{MR1893917}
\@writefile{toc}{\contentsline {section}{\numberline {3}Hyperbolic-orbit Algorithm}{6}{section.3}\protected@file@percent }
\@writefile{lof}{\contentsline {figure}{\numberline {1}{\ignorespaces The computational graph of case 1.}}{7}{figure.1}\protected@file@percent }
\@writefile{lof}{\contentsline {figure}{\numberline {2}{\ignorespaces An illustration on how to embed \textbf  {any} given product of matrices $AB$ in \textbf  {any neural network models} to hyperbolic space $\mathbb  {H}^2$.}}{8}{figure.2}\protected@file@percent }
\@writefile{lof}{\contentsline {figure}{\numberline {3}{\ignorespaces Gradients of the hyperbolic-length product.}}{9}{figure.3}\protected@file@percent }
\citation{vaswani2017attention}
\citation{chuang2022hausdorff}
\@writefile{lof}{\contentsline {figure}{\numberline {4}{\ignorespaces The computational graph of Case 2 when a hyperbolic-length product is implemented to the model directly before training.}}{10}{figure.4}\protected@file@percent }
\@writefile{toc}{\contentsline {section}{\numberline {4}Examples}{10}{section.4}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {4.1}Self-attention mechanism in any transformer-based models with the hyperbolic-length product implemented before training}{10}{subsection.4.1}\protected@file@percent }
\citation{blum1988training}
\citation{cheng1980existence}
\@writefile{toc}{\contentsline {section}{\numberline {5}Discussion}{11}{section.5}\protected@file@percent }
\citation{chuang2015implications}
\@writefile{toc}{\contentsline {section}{\numberline {6}Limitation}{12}{section.6}\protected@file@percent }
\bibstyle{amsplain}
\bibdata{refs}
\bibcite{MR725161}{1}
\bibcite{beardon2012geometry}{2}
\bibcite{blum1988training}{3}
\bibcite{cheng1980existence}{4}
\bibcite{chuang2022hausdorff}{5}
\bibcite{chuang2015implications}{6}
\bibcite{judd1990neural}{7}
\bibcite{MR1138441}{8}
\bibcite{MR2402415}{9}
\bibcite{MR4221225}{10}
\bibcite{MR1893917}{11}
\bibcite{tu2011manifolds}{12}
\bibcite{vaswani2017attention}{13}
\bibcite{yun2017global}{14}
\gdef \@abspage@last{14}
